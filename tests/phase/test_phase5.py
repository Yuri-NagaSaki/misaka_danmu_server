"""
Phase 5 è¿ç§»å·¥å…·æµ‹è¯•è„šæœ¬

æµ‹è¯•Alembicè¿ç§»å’Œæ•°æ®åº“schemaåˆ›å»ºåŠŸèƒ½
"""

import asyncio
import logging
import os
from pathlib import Path
import sys
import subprocess

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root / "src"))

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


async def test_alembic_configuration():
    """æµ‹è¯•Alembicé…ç½®"""
    try:
        logger.info("æµ‹è¯•Alembicé…ç½®...")
        
        # æ£€æŸ¥Alembicé…ç½®æ–‡ä»¶
        alembic_ini = project_root / "alembic.ini"
        if not alembic_ini.exists():
            raise FileNotFoundError("alembic.iniæ–‡ä»¶ä¸å­˜åœ¨")
        
        # æ£€æŸ¥Alembicç›®å½•
        alembic_dir = project_root / "alembic"
        if not alembic_dir.exists():
            raise FileNotFoundError("alembicç›®å½•ä¸å­˜åœ¨")
        
        # æ£€æŸ¥env.pyæ–‡ä»¶
        env_py = alembic_dir / "env.py"
        if not env_py.exists():
            raise FileNotFoundError("alembic/env.pyæ–‡ä»¶ä¸å­˜åœ¨")
        
        # æ£€æŸ¥ç‰ˆæœ¬ç›®å½•
        versions_dir = alembic_dir / "versions"
        if not versions_dir.exists():
            raise FileNotFoundError("alembic/versionsç›®å½•ä¸å­˜åœ¨")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è¿ç§»æ–‡ä»¶
        migration_files = list(versions_dir.glob("*.py"))
        if not migration_files:
            logger.warning("âš ï¸  æ²¡æœ‰æ‰¾åˆ°è¿ç§»æ–‡ä»¶")
        else:
            logger.info(f"ğŸ“ æ‰¾åˆ° {len(migration_files)} ä¸ªè¿ç§»æ–‡ä»¶")
            for file in migration_files:
                logger.info(f"  - {file.name}")
        
        logger.info("âœ… Alembicé…ç½®æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Alembicé…ç½®æµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_offline_schema_validation():
    """æµ‹è¯•ç¦»çº¿schemaéªŒè¯"""
    try:
        logger.info("æµ‹è¯•ç¦»çº¿schemaéªŒè¯...")
        
        # è¿è¡Œç¦»çº¿éªŒè¯è„šæœ¬
        result = subprocess.run(
            [sys.executable, "validate_schema.py"],
            capture_output=True,
            text=True,
            cwd=project_root
        )
        
        if result.returncode == 0:
            logger.info("âœ… ç¦»çº¿schemaéªŒè¯é€šè¿‡")
            
            # æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶
            schema_file = project_root / "generated_schema.sql"
            if schema_file.exists():
                logger.info(f"ğŸ“„ ç”Ÿæˆçš„schemaæ–‡ä»¶å¤§å°: {schema_file.stat().st_size} bytes")
            
            return True
        else:
            logger.error(f"âŒ ç¦»çº¿schemaéªŒè¯å¤±è´¥: {result.stderr}")
            return False
            
    except Exception as e:
        logger.error(f"âŒ ç¦»çº¿schemaéªŒè¯æµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_model_imports():
    """æµ‹è¯•æ¨¡å‹å¯¼å…¥"""
    try:
        logger.info("æµ‹è¯•æ¨¡å‹å¯¼å…¥...")
        
        # å¯¼å…¥æ‰€æœ‰æ¨¡å‹
        from src.database.models.base import Base, IDMixin, TimestampMixin
        from src.database.models.anime import Anime, AnimeType, AnimeSource, AnimeMetadata, AnimeAlias, TMDBEpisodeMapping
        from src.database.models.episode import Episode, Comment
        from src.database.models.user import User, APIToken, TokenAccessLog, BangumiAuth, OAuthState, UARules
        from src.database.models.system import Config, CacheData, Scraper, ScheduledTask, TaskHistory
        
        # æ£€æŸ¥æ¨¡å‹æ•°é‡
        model_count = len(Base.registry._class_registry)
        logger.info(f"ğŸ“Š æˆåŠŸå¯¼å…¥ {model_count} ä¸ªæ¨¡å‹")
        
        # æ£€æŸ¥åŸºç¡€æ¨¡å‹å±æ€§
        test_models = [
            ("Anime", Anime),
            ("Episode", Episode),
            ("Comment", Comment),
            ("User", User),
            ("APIToken", APIToken)
        ]
        
        for model_name, model_class in test_models:
            if hasattr(model_class, '__tablename__'):
                logger.info(f"  âœ… {model_name} -> è¡¨å: {model_class.__tablename__}")
            else:
                logger.warning(f"  âš ï¸  {model_name} æ²¡æœ‰__tablename__å±æ€§")
        
        # æ£€æŸ¥å…ƒæ•°æ®
        metadata = Base.metadata
        logger.info(f"ğŸ“‹ å…ƒæ•°æ®åŒ…å« {len(metadata.tables)} ä¸ªè¡¨")
        
        logger.info("âœ… æ¨¡å‹å¯¼å…¥æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ¨¡å‹å¯¼å…¥æµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_database_configuration():
    """æµ‹è¯•æ•°æ®åº“é…ç½®"""
    try:
        logger.info("æµ‹è¯•æ•°æ®åº“é…ç½®...")
        
        from src.config import DatabaseConfig
        
        # æµ‹è¯•é»˜è®¤é…ç½®
        config = DatabaseConfig()
        logger.info(f"ğŸ“Š é»˜è®¤æ•°æ®åº“ç±»å‹: {config.type}")
        
        # æµ‹è¯•PostgreSQLé…ç½®
        pg_config = DatabaseConfig(
            type="postgresql",
            host="test.example.com",
            port=5432,
            user="testuser",
            password="testpass",
            name="testdb"
        )
        
        # æµ‹è¯•URLç”Ÿæˆ
        async_url = pg_config.async_url
        sync_url = pg_config.sync_url
        
        logger.info(f"ğŸ”— å¼‚æ­¥URLæ ¼å¼: {async_url.split('@')[0]}@***")
        logger.info(f"ğŸ”— åŒæ­¥URLæ ¼å¼: {sync_url.split('@')[0]}@***")
        
        # æµ‹è¯•MySQLé…ç½®
        mysql_config = DatabaseConfig(
            type="mysql",
            host="test.example.com",
            port=3306,
            user="testuser",
            password="testpass",
            name="testdb"
        )
        
        mysql_sync_url = mysql_config.sync_url
        logger.info(f"ğŸ”— MySQL URLæ ¼å¼: {mysql_sync_url.split('@')[0]}@***")
        
        logger.info("âœ… æ•°æ®åº“é…ç½®æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“é…ç½®æµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_sql_generation():
    """æµ‹è¯•SQLç”Ÿæˆ"""
    try:
        logger.info("æµ‹è¯•SQLç”Ÿæˆ...")
        
        from sqlalchemy import create_mock_engine
        from src.database.models.base import Base
        
        def capture_sql(sql, *multiparams, **params):
            captured_sql.append(str(sql.compile(dialect=engine.dialect)))
            return ""
        
        captured_sql = []
        engine = create_mock_engine("postgresql://", capture_sql)
        
        # ç”Ÿæˆåˆ›å»ºè¡¨çš„SQL
        Base.metadata.create_all(engine, checkfirst=False)
        
        if captured_sql:
            logger.info(f"ğŸ“ ç”Ÿæˆäº† {len(captured_sql)} æ¡SQLè¯­å¥")
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            sql_output = project_root / "test_generated.sql"
            with open(sql_output, "w", encoding="utf-8") as f:
                f.write("-- Test Generated SQL\n\n")
                f.write("\n\n".join(captured_sql))
            
            logger.info(f"ğŸ’¾ SQLå·²ä¿å­˜åˆ°: {sql_output}")
            
            # æ£€æŸ¥å…³é”®è¡¨çš„SQL
            key_tables = ["anime", "episode", "comment", "users"]
            for table in key_tables:
                found = any(table in sql.lower() for sql in captured_sql)
                if found:
                    logger.info(f"  âœ… æ‰¾åˆ°è¡¨ {table} çš„SQL")
                else:
                    logger.warning(f"  âš ï¸  æœªæ‰¾åˆ°è¡¨ {table} çš„SQL")
        
        logger.info("âœ… SQLç”Ÿæˆæµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        logger.error(f"âŒ SQLç”Ÿæˆæµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_environment_variables():
    """æµ‹è¯•ç¯å¢ƒå˜é‡æ”¯æŒ"""
    try:
        logger.info("æµ‹è¯•ç¯å¢ƒå˜é‡æ”¯æŒ...")
        
        # æ£€æŸ¥.env.exampleæ–‡ä»¶æ˜¯å¦åˆ›å»º
        env_example = project_root / ".env.example"
        if env_example.exists():
            logger.info("âœ… .env.exampleæ–‡ä»¶å­˜åœ¨")
            with open(env_example, "r", encoding="utf-8") as f:
                content = f.read()
                if "DB_HOST" in content:
                    logger.info("  âœ… åŒ…å«æ•°æ®åº“é…ç½®å˜é‡")
                else:
                    logger.warning("  âš ï¸  ç¼ºå°‘æ•°æ®åº“é…ç½®å˜é‡")
        else:
            logger.warning("âš ï¸  .env.exampleæ–‡ä»¶ä¸å­˜åœ¨")
        
        # æµ‹è¯•ç¯å¢ƒå˜é‡è¯»å–
        original_host = os.environ.get("DB_HOST")
        os.environ["DB_HOST"] = "test.example.com"
        
        from src.config import DatabaseConfig
        config = DatabaseConfig()
        
        # æ¢å¤åŸå§‹å€¼
        if original_host:
            os.environ["DB_HOST"] = original_host
        else:
            os.environ.pop("DB_HOST", None)
        
        logger.info("âœ… ç¯å¢ƒå˜é‡æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ç¯å¢ƒå˜é‡æµ‹è¯•å¤±è´¥: {e}")
        return False


async def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    logger.info("ğŸš€ å¼€å§‹ Phase 5 è¿ç§»å·¥å…·æµ‹è¯•")
    logger.info("=" * 60)
    
    tests = [
        ("Alembicé…ç½®", test_alembic_configuration),
        ("æ¨¡å‹å¯¼å…¥", test_model_imports),
        ("æ•°æ®åº“é…ç½®", test_database_configuration),
        ("ç¦»çº¿SchemaéªŒè¯", test_offline_schema_validation),
        ("SQLç”Ÿæˆ", test_sql_generation),
        ("ç¯å¢ƒå˜é‡æ”¯æŒ", test_environment_variables),
    ]
    
    results = []
    for test_name, test_func in tests:
        logger.info(f"\\nğŸ“ æµ‹è¯•: {test_name}")
        logger.info("-" * 30)
        result = await test_func()
        results.append((test_name, result))
    
    # æ€»ç»“ç»“æœ
    logger.info("\\n" + "=" * 60)
    logger.info("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“:")
    
    passed = 0
    for test_name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        logger.info(f"  {test_name}: {status}")
        if result:
            passed += 1
    
    logger.info(f"\\næ€»è®¡: {passed}/{len(tests)} æµ‹è¯•é€šè¿‡")
    
    if passed == len(tests):
        logger.info("ğŸ‰ Phase 5 è¿ç§»å·¥å…·å®ç°å®Œæˆï¼")
        logger.info("\\nå·²å®Œæˆçš„å·¥ä½œ:")
        logger.info("  âœ… Alembicè¿ç§»ç¯å¢ƒé…ç½®")
        logger.info("  âœ… PostgreSQLæ•°æ®åº“schemaå®šä¹‰")
        logger.info("  âœ… å®Œæ•´çš„ORMæ¨¡å‹éªŒè¯")
        logger.info("  âœ… ç¦»çº¿schemaéªŒè¯å·¥å…·")
        logger.info("  âœ… æ•°æ®åº“åˆå§‹åŒ–è„šæœ¬")
        logger.info("  âœ… ç¯å¢ƒå˜é‡é…ç½®æ”¯æŒ")
        logger.info("\\næ ¸å¿ƒç‰¹æ€§:")
        logger.info("  ğŸ—„ï¸  å®Œæ•´çš„PostgreSQL schema")
        logger.info("  ğŸ”§ Alembicæ•°æ®åº“è¿ç§»ç®¡ç†")
        logger.info("  âœ… ç¦»çº¿schemaéªŒè¯å’ŒSQLç”Ÿæˆ")
        logger.info("  ğŸ” æ”¯æŒç¯å¢ƒå˜é‡é…ç½®")
        logger.info("  ğŸ“Š æ•°æ®åº“å¥åº·æ£€æŸ¥å’Œåˆå§‹åŒ–")
        logger.info("  ğŸ—ï¸  æ”¯æŒå¤šæ•°æ®åº“ç±»å‹ï¼ˆMySQL/PostgreSQLï¼‰")
        logger.info("\\nä¸‹ä¸€æ­¥å¯ä»¥è¿›è¡Œ:")
        logger.info("  1. éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ")
        logger.info("  2. é›†æˆåˆ°CI/CDæµæ°´çº¿")
        logger.info("  3. æ·»åŠ æ•°æ®åº“ç›‘æ§å’Œå¤‡ä»½")
    else:
        logger.error("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦ä¿®å¤åå†ç»§ç»­")
    
    return passed == len(tests)


if __name__ == "__main__":
    asyncio.run(main())