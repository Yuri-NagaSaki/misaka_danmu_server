"""
Phase 2 æ¨¡å‹æµ‹è¯•è„šæœ¬

æµ‹è¯•SQLAlchemy ORMæ¨¡å‹æ˜¯å¦æ­£ç¡®å®šä¹‰
"""

import asyncio
import logging
from pathlib import Path
import sys

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root / "src"))

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


async def test_model_imports():
    """æµ‹è¯•æ¨¡å‹å¯¼å…¥"""
    try:
        logger.info("æµ‹è¯•æ¨¡å‹å¯¼å…¥...")
        
        # æµ‹è¯•åŸºç±»å¯¼å…¥
        from src.database.models.base import Base, IDMixin, TimestampMixin
        
        # æµ‹è¯•ç•ªå‰§æ¨¡å‹å¯¼å…¥
        from src.database.models.anime import (
            AnimeType, Anime, AnimeSource, AnimeMetadata, 
            AnimeAlias, TMDBEpisodeMapping
        )
        
        # æµ‹è¯•åˆ†é›†æ¨¡å‹å¯¼å…¥
        from src.database.models.episode import Episode, Comment
        
        # æµ‹è¯•ç”¨æˆ·æ¨¡å‹å¯¼å…¥
        from src.database.models.user import (
            User, APIToken, TokenAccessLog, BangumiAuth, 
            OAuthState, UARules
        )
        
        # æµ‹è¯•ç³»ç»Ÿæ¨¡å‹å¯¼å…¥
        from src.database.models.system import (
            Config, CacheData, Scraper, ScheduledTask, TaskHistory
        )
        
        # æµ‹è¯•ç»Ÿä¸€å¯¼å…¥
        from src.database.models import Base as ModelsBase
        assert Base is ModelsBase
        
        logger.info("âœ… æ¨¡å‹å¯¼å…¥æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ¨¡å‹å¯¼å…¥æµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_model_metadata():
    """æµ‹è¯•æ¨¡å‹å…ƒæ•°æ®"""
    try:
        logger.info("æµ‹è¯•æ¨¡å‹å…ƒæ•°æ®...")
        
        from src.database.models import Base
        
        # æ£€æŸ¥å…ƒæ•°æ®
        metadata = Base.metadata
        logger.info(f"å‘ç° {len(metadata.tables)} ä¸ªæ•°æ®è¡¨")
        
        # åˆ—å‡ºæ‰€æœ‰è¡¨
        table_names = list(metadata.tables.keys())
        expected_tables = {
            'anime', 'anime_sources', 'anime_metadata', 'anime_aliases', 
            'tmdb_episode_mapping', 'episode', 'comment', 'users', 
            'api_tokens', 'token_access_logs', 'bangumi_auth', 'oauth_states',
            'ua_rules', 'config', 'cache_data', 'scrapers', 
            'scheduled_tasks', 'task_history'
        }
        
        logger.info(f"æœŸæœ›è¡¨: {len(expected_tables)}")
        logger.info(f"å‘ç°è¡¨: {table_names}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é—æ¼çš„è¡¨
        missing_tables = expected_tables - set(table_names)
        extra_tables = set(table_names) - expected_tables
        
        if missing_tables:
            logger.error(f"ç¼ºå°‘è¡¨: {missing_tables}")
            return False
        
        if extra_tables:
            logger.warning(f"é¢å¤–çš„è¡¨: {extra_tables}")
        
        logger.info("âœ… æ¨¡å‹å…ƒæ•°æ®æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ¨¡å‹å…ƒæ•°æ®æµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_model_relationships():
    """æµ‹è¯•æ¨¡å‹å…³ç³»"""
    try:
        logger.info("æµ‹è¯•æ¨¡å‹å…³ç³»...")
        
        from src.database.models import Anime, AnimeSource, Episode, Comment, User, APIToken
        
        # æµ‹è¯•Animeå…³ç³»
        anime_relationships = [
            'sources', 'anime_metadata', 'aliases'
        ]
        for rel_name in anime_relationships:
            assert hasattr(Anime, rel_name), f"Animeç¼ºå°‘å…³ç³»: {rel_name}"
        
        # æµ‹è¯•AnimeSourceå…³ç³»
        assert hasattr(AnimeSource, 'anime'), "AnimeSourceç¼ºå°‘animeå…³ç³»"
        assert hasattr(AnimeSource, 'episodes'), "AnimeSourceç¼ºå°‘episodeså…³ç³»"
        
        # æµ‹è¯•Episodeå…³ç³»
        assert hasattr(Episode, 'source'), "Episodeç¼ºå°‘sourceå…³ç³»"
        assert hasattr(Episode, 'comments'), "Episodeç¼ºå°‘commentså…³ç³»"
        
        # æµ‹è¯•Commentå…³ç³»
        assert hasattr(Comment, 'episode'), "Commentç¼ºå°‘episodeå…³ç³»"
        
        # æµ‹è¯•Userå…³ç³»
        assert hasattr(User, 'bangumi_auth'), "Userç¼ºå°‘bangumi_authå…³ç³»"
        assert hasattr(User, 'oauth_states'), "Userç¼ºå°‘oauth_stateså…³ç³»"
        
        # æµ‹è¯•APITokenå…³ç³»
        assert hasattr(APIToken, 'access_logs'), "APITokenç¼ºå°‘access_logså…³ç³»"
        
        logger.info("âœ… æ¨¡å‹å…³ç³»æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ¨¡å‹å…³ç³»æµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_model_constraints():
    """æµ‹è¯•æ¨¡å‹çº¦æŸ"""
    try:
        logger.info("æµ‹è¯•æ¨¡å‹çº¦æŸ...")
        
        from src.database.models import Base
        
        # æ£€æŸ¥è¡¨çš„çº¦æŸ
        constraint_count = 0
        index_count = 0
        
        for table_name, table in Base.metadata.tables.items():
            # ç»Ÿè®¡çº¦æŸ
            constraint_count += len(table.constraints)
            # ç»Ÿè®¡ç´¢å¼•
            index_count += len(table.indexes)
        
        logger.info(f"æ€»çº¦æŸæ•°: {constraint_count}")
        logger.info(f"æ€»ç´¢å¼•æ•°: {index_count}")
        
        # æ£€æŸ¥å…³é”®è¡¨çš„çº¦æŸ
        anime_table = Base.metadata.tables['anime']
        assert len(anime_table.indexes) > 0, "animeè¡¨ç¼ºå°‘ç´¢å¼•"
        
        comment_table = Base.metadata.tables['comment']
        assert len(comment_table.indexes) > 0, "commentè¡¨ç¼ºå°‘ç´¢å¼•"
        
        logger.info("âœ… æ¨¡å‹çº¦æŸæµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ¨¡å‹çº¦æŸæµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_alembic_migration_generation():
    """æµ‹è¯•Alembicè¿ç§»ç”Ÿæˆ"""
    try:
        logger.info("æµ‹è¯•Alembicè¿ç§»ç”Ÿæˆ...")
        
        # å¯¼å…¥Alembicç›¸å…³æ¨¡å—
        from alembic.config import Config
        from alembic.script import ScriptDirectory
        from alembic import command
        import tempfile
        import os
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        with tempfile.TemporaryDirectory() as temp_dir:
            # å¤åˆ¶alembicé…ç½®åˆ°ä¸´æ—¶ç›®å½•
            alembic_cfg_path = project_root / "alembic.ini"
            temp_alembic_cfg = Path(temp_dir) / "alembic.ini"
            
            # è¯»å–åŸé…ç½®
            with open(alembic_cfg_path, 'r') as f:
                alembic_config_content = f.read()
            
            # ä¿®æ”¹é…ç½®æŒ‡å‘ä¸´æ—¶ç›®å½•
            alembic_config_content = alembic_config_content.replace(
                "script_location = alembic",
                f"script_location = {temp_dir}/alembic"
            )
            
            # å†™å…¥ä¸´æ—¶é…ç½®
            with open(temp_alembic_cfg, 'w') as f:
                f.write(alembic_config_content)
            
            # åˆ›å»ºä¸´æ—¶alembicç›®å½•ç»“æ„
            temp_alembic_dir = Path(temp_dir) / "alembic"
            temp_alembic_dir.mkdir()
            
            # å¤åˆ¶env.py
            import shutil
            shutil.copy(project_root / "alembic" / "env.py", temp_alembic_dir / "env.py")
            shutil.copy(project_root / "alembic" / "script.py.mako", temp_alembic_dir / "script.py.mako")
            (temp_alembic_dir / "versions").mkdir()
            
            # åˆ›å»ºAlembicé…ç½®å¯¹è±¡
            alembic_cfg = Config(str(temp_alembic_cfg))
            
            try:
                # å°è¯•ç”Ÿæˆåˆå§‹è¿ç§»
                command.revision(alembic_cfg, message="Initial migration", autogenerate=False)
                
                # æ£€æŸ¥æ˜¯å¦ç”Ÿæˆäº†è¿ç§»æ–‡ä»¶
                versions_dir = temp_alembic_dir / "versions"
                migration_files = list(versions_dir.glob("*.py"))
                
                if migration_files:
                    logger.info(f"æˆåŠŸç”Ÿæˆè¿ç§»æ–‡ä»¶: {migration_files[0].name}")
                    
                    # è¯»å–è¿ç§»æ–‡ä»¶å†…å®¹
                    with open(migration_files[0], 'r') as f:
                        migration_content = f.read()
                    
                    if 'def upgrade()' in migration_content and 'def downgrade()' in migration_content:
                        logger.info("âœ… Alembicè¿ç§»ç”Ÿæˆæµ‹è¯•é€šè¿‡")
                        return True
                    else:
                        logger.error("ç”Ÿæˆçš„è¿ç§»æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®")
                        return False
                else:
                    logger.error("æœªç”Ÿæˆè¿ç§»æ–‡ä»¶")
                    return False
            
            except Exception as e:
                # å¦‚æœä¸èƒ½è¿æ¥æ•°æ®åº“ï¼Œè¿™æ˜¯é¢„æœŸçš„
                if "æ•°æ®åº“è¿æ¥" in str(e) or "connect" in str(e).lower():
                    logger.info("âœ… Alembicé…ç½®æ­£ç¡®ï¼ˆæ— æ³•è¿æ¥æ•°æ®åº“æ˜¯é¢„æœŸçš„ï¼‰")
                    return True
                else:
                    raise
        
    except Exception as e:
        logger.error(f"âŒ Alembicè¿ç§»ç”Ÿæˆæµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_database_optimization():
    """æµ‹è¯•æ•°æ®åº“ä¼˜åŒ–é…ç½®"""
    try:
        logger.info("æµ‹è¯•æ•°æ®åº“ä¼˜åŒ–é…ç½®...")
        
        from src.database.optimization import (
            DatabaseOptimizer, configure_database_optimizations,
            get_database_specific_indexes
        )
        
        # æµ‹è¯•ä¼˜åŒ–å™¨ç±»
        optimizer = DatabaseOptimizer()
        assert hasattr(optimizer, 'configure_mysql_optimizations')
        assert hasattr(optimizer, 'configure_postgresql_optimizations')
        assert hasattr(optimizer, 'configure_sqlite_optimizations')
        
        # æµ‹è¯•è¿æ¥æ± é…ç½®
        mysql_config = optimizer.configure_connection_pool('mysql')
        postgresql_config = optimizer.configure_connection_pool('postgresql')
        sqlite_config = optimizer.configure_connection_pool('sqlite')
        
        assert 'pool_size' in mysql_config
        assert 'pool_size' in postgresql_config
        assert 'poolclass' in sqlite_config
        
        # æµ‹è¯•ç´¢å¼•é…ç½®
        mysql_indexes = get_database_specific_indexes('mysql')
        postgresql_indexes = get_database_specific_indexes('postgresql')
        sqlite_indexes = get_database_specific_indexes('sqlite')
        
        assert 'anime' in mysql_indexes
        assert 'anime' in postgresql_indexes
        assert 'anime' in sqlite_indexes
        
        logger.info("âœ… æ•°æ®åº“ä¼˜åŒ–é…ç½®æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“ä¼˜åŒ–é…ç½®æµ‹è¯•å¤±è´¥: {e}")
        return False


async def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    logger.info("ğŸš€ å¼€å§‹ Phase 2 æ¨¡å‹å®šä¹‰æµ‹è¯•")
    logger.info("=" * 50)
    
    tests = [
        ("æ¨¡å‹å¯¼å…¥", test_model_imports),
        ("æ¨¡å‹å…ƒæ•°æ®", test_model_metadata),
        ("æ¨¡å‹å…³ç³»", test_model_relationships),
        ("æ¨¡å‹çº¦æŸ", test_model_constraints),
        ("Alembicè¿ç§»", test_alembic_migration_generation),
        ("æ•°æ®åº“ä¼˜åŒ–", test_database_optimization),
    ]
    
    results = []
    for test_name, test_func in tests:
        logger.info(f"\nğŸ“ æµ‹è¯•: {test_name}")
        logger.info("-" * 30)
        result = await test_func()
        results.append((test_name, result))
    
    # æ€»ç»“ç»“æœ
    logger.info("\n" + "=" * 50)
    logger.info("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“:")
    
    passed = 0
    for test_name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        logger.info(f"  {test_name}: {status}")
        if result:
            passed += 1
    
    logger.info(f"\næ€»è®¡: {passed}/{len(tests)} æµ‹è¯•é€šè¿‡")
    
    if passed == len(tests):
        logger.info("ğŸ‰ Phase 2 æ ¸å¿ƒæ¨¡å‹å®šä¹‰å®Œæˆï¼")
        logger.info("\nå·²å®Œæˆçš„å·¥ä½œ:")
        logger.info("  âœ… 15ä¸ªæ•°æ®åº“è¡¨çš„ORMæ¨¡å‹")
        logger.info("  âœ… å®Œæ•´çš„è¡¨å…³ç³»å’Œçº¦æŸå®šä¹‰")
        logger.info("  âœ… æ•°æ®åº“ç‰¹å®šä¼˜åŒ–é…ç½®")
        logger.info("  âœ… Alembicè¿ç§»æ”¯æŒ")
        logger.info("\nä¸‹ä¸€æ­¥å¯ä»¥è¿›è¡Œ:")
        logger.info("  1. Phase 3: Repositoryæ¨¡å¼å®ç°")
        logger.info("  2. ç”Ÿæˆå’Œæ‰§è¡Œæ•°æ®åº“è¿ç§»")
        logger.info("  3. åˆ›å»ºç¬¬ä¸€ä¸ªRepositoryç±»")
    else:
        logger.error("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦ä¿®å¤åå†ç»§ç»­")
    
    return passed == len(tests)


if __name__ == "__main__":
    asyncio.run(main())